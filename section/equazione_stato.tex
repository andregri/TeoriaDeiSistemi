\documentclass[../main.tex]{subfiles}

\begin{document}
	\section{Equazione di stato}
		Abbiamo visto che i sistemi MIMO possono essere rappresentati attraverso un sistema di equazioni differenziali o in forma matriciale.
		\begin{center}
			\begin{minipage}{.9\linewidth}
				L'equazione di stato \'e una rappresentazione dei sistemi dinamici (non necessariamente lineare) che mette in relazione ingressi e uscite sfruttando una quantit\'a (interna al sistema) detta \textit{stato del sistema}.
			\end{minipage}
		\end{center}
		Lo stato $ \vec{x}(t) $ rappresenta una \textit{foto istantanea} di $ S $ e deve descriverne completamente la situazione. Per determinare $ \vec{x}(t) $ per $ t \geq t_0 $ saranno sufficienti $ \vec{x}(t^-_0) $ e $ \vec u(\tau) $ per $ \tau \geq t_0 $.
		\[
			\begin{aligned}
				\vec{y}(t) &=
				\begin{bmatrix}
					y_1(t)
					\\ \vdots \\
					y_{n_y}(t)
				\end{bmatrix}
				\\
				n_y &= dim(\vec{y}(t))
			\end{aligned}
			\qquad
			\begin{aligned}
				\vec{u}(t) &=
				\begin{bmatrix}
					u_1(t)
					\\ \vdots \\
					u_{n_u}(t)
				\end{bmatrix}
				\\
				n_u &= dim(\vec{u}(t))
			\end{aligned}
			\qquad
			\begin{aligned}
				\vec{x}(t) &=
				\begin{bmatrix}
					x_1(t)
					\\ \vdots \\
					y_{n_x}(t)
				\end{bmatrix}
				\\
				n_x &= dim(\vec{x}(t))
			\end{aligned}
		\]
		
		Le equazioni per descrivere il sistema in notazione matriciale saranno:
		\begin{align*}
			\vec{\dot{x}}(t) &= A \vec{x}(t) + B \vec{u}(t)
			\\
			\vec{y}(t) &= C \vec{x}(t) + D \vec{u}(t)
		\end{align*}
		dove le dimensioni delle matrici sono:
		\[
			A \in \R^{n_x x\ n_x} \qquad B \in \R^{n_x x\ n_u} \qquad C \in \R^{n_y x\ n_x} \qquad D \in \R^{n_y x\ n_u}
		\]
		
		Si nota dalla seconda equazione che il vettore delle uscite dipende istantaneamente dalla stato $ (\vec x) $ e dal controllo $ (\vec u) $.
		
		Dalla prima equazione invece vediamo che lo stato dipende dinamicamente dallo stato stesso e dal controllo.
		
		Scrivendo esplicitamente le due equazioni otteniamo:
		\newcommand{\eq}[3]{#2_{#3 1} #1_1(t) + #2_{#3 2} #1_2(t) + \cdots + #2_{#3 n_#1} #1_{n_#1}(t)}
		\begin{align*}
			\dot x_1(t) &= \eq{x}{a}{1} && + \eq{u}{b}{1}\\
			&\vdots\\
			\dot x_{n_x}(t) &= \eq{x}{a}{n_x} && + \eq{u}{b}{n_x}\\
			\smallskip\\
			y_1(t) &= \eq{x}{c}{1} && + \eq{u}{d}{1}\\
			&\vdots\\
			y_{n_y}(t) &= \eq{x}{c}{n_y} && + \eq{u}{d}{n_y}\\
		\end{align*}
		
	\section{Soluzione dell'equazione di stato}
		Significa trovare $ \vec x(t) $ e di conseguenza $ \vec y(t) $, dati $ \vec x(t_0^-) $ e $ u(\tau) $ per $ \tau \in [0, t_0] $.
		
		Si dimostra che:
		\[
			\vec x(t) = C e^{At} \vec x(0^-) + C \int_{0^-}^{t} e^{A(t-\tau)} B \vec u(\tau) d\tau + D \vec u(t)
		\]
		dove:
		\begin{itemize}
			\item 
				$ e^{At} \vec x(0^-) \quad $ evoluzione libera dello stato. \'E l'uscita che dipende solo dalle $ n_x $ condizioni iniziali, pertanto si chiama vettore delle uscite libere.
			\item
				$ \int_{0^-}^{t} e^{A(t-\tau)} B \vec u(\tau) d\tau \quad $ integrale di convoluzione che rappresenta l'evoluzione forzata dello stato.
		\end{itemize}
	
	\subsection{Come si calcola $ e^{At} $}
		\[
			e^{At} = I + \dfrac{At}{1!} + \dfrac{(At)^2}{2!} + \dfrac{(At)^3}{3!} + \dots = \sum_{k=0}^{k=\infty} \dfrac{A^k t^k}{k!}
		\]
		Per effettuare questo calcolo distinguiamo vari casi:
		\begin{itemize}
			\item 
				$ A^k = 0\ \text{per}\ k \geq \bar k $ (matrice nil-potente di ordine $ \bar k $): usare la formula esplicitamente.
				
				\begin{mdframed}[style=Esempio]
					\paragraph{Esempio}
						\[
							A =
							\begin{bmatrix}
								0 & 1\\ 0 & 0
							\end{bmatrix}
							\qquad
							A^2 = 
							\begin{bmatrix}
								0 & 0\\ 0 & 0
							\end{bmatrix}
							\qquad
							A^k =
							\begin{bmatrix}
								0 & 1\\ 0 & 0
							\end{bmatrix}
						\]
						Abbiamo trovato che A \'e una matrice nil-potente di ordine 2.
						\[ 
							e^{At} = I + At = 
							\begin{bmatrix}
								1 & 0\\
								0 & 1
							\end{bmatrix} +
							\begin{bmatrix}
								0 & t\\
								0 & 0
							\end{bmatrix} = 
							\begin{bmatrix}
								1 & t\\
								0 & 1
							\end{bmatrix}
						\]
				\end{mdframed}
			\item
				A \'e una matrice diagonale:
				\[
					e^{At} =
					\begin{bmatrix}
						\dfrac{\lambda_1^k t^k}{k!} & \dots & 0
						\\
						\vdots & \ddots & \vdots
						\\
						0 & \dots & \dfrac{\lambda_{n_x}^k t^k}{k!}
					\end{bmatrix} = 
					\begin{bmatrix}
						e^{\lambda_1 t} & \dots & 0
						\\[0.5em]
						\vdots & \ddots & \vdots
						\\[0.5em]
						0 & \dots & e^{\lambda_{n_x} t}
					\end{bmatrix}
				\]
			\item
				Negli altri casi usiamo questa formula che verr\'a chiarita in seguito:
				\[
					e^{At} = \aLbrace{(sI-A)^{-1}}
				\]
				
				\begin{mdframed}[style=Esempio]
					\paragraph{Esempio}
					Ripetiamo il calcolo dell'esempio precedente con $ A = \begin{bmatrix} 0 & 1\\ 0 & 0 \end{bmatrix} $
					\[
						e^{At} = \aLbrace{(sI-A)^{-1}} =
						\aLbrace{
							\begin{bmatrix}
								\dfrac{1}{s} & \dfrac{1}{s^2}
								\\[0.5em]
								0 & \dfrac{1}{s}
							\end{bmatrix}
						} = 
						\begin{bmatrix}
							1 & t\\
							0 & 1
						\end{bmatrix} 1(t)
					\]
				\end{mdframed}
		\end{itemize}
	
	\subsection{Polinomio caratteristico}
		Data una matrice quadrata A, il polinomio caratteristico \'e definito come:
		\[ 
			\varphi(s) = det(sI - A)
		\]
		Inoltre si pu\'o calcolare come il m.c.m. dei denominatori di tutti i determinanti diversi da zero di tutte le sottomatrici quadrate di $ (sI-A)^{-1} $. Questo metodo pu\'o essere utile nel caso in cui ci venga fornita direttamente $ (sI-A)^{-1} $ oppure la matrice non sia quadrata.
		
		\begin{mdframed}[style=Esempio]
			\paragraph{Esempio}
			\[ 
				A = 
				\begin{bmatrix}
					1 & 0\\
					0 & 2
				\end{bmatrix}
			\]
			\[
				\varphi(s) = det \left( s 
				\begin{bmatrix}
					1 & 0\\
					0 & 1
				\end{bmatrix} -
				\begin{bmatrix}
					1 & 0\\
					0 & 2
				\end{bmatrix} \right) = det \left( 
				\begin{bmatrix}
					s-1 & 0\\
					0 & s-2
				\end{bmatrix} \right) = (s-1)(s-2)
			\]
			Gli autovalori sono: $ s_1 = 1 \quad s_2 = 2 $ entrambi con molteplicit\'a 1.
		\end{mdframed}
		
		\begin{mdframed}[style=Esempio]
			\paragraph{Esempio}
			Usiamo il secondo metodo per calcolare il polinomio caratteristico data:
			\[
				(sI-A)^{-1} =
				\begin{bmatrix}
					\dfrac{1}{s} & 0\\
					0 & \dfrac{1}{s}
				\end{bmatrix}
			\]
			Il suo determinante \'e: $ det (sI-A)^{-1} = \dfrac{1}{s^2} $.\\
			Ci sono 5 sottomatrici: 4 sono i singoli elementi, il quinto \'e la matrice stessa:
			\[
				\varphi(s) = mcm(s, s, s^2) = s^2
			\]
		\end{mdframed}
		
	\subsubsection{Propriet\'a}
		\begin{itemize}
			\item 
				$ \varphi(s) $ \'e un polinomio annullante per A se $ \varphi(A) = [0] $ (matrice nulla).
			\item 
				Il suo grado \'e: $ \pDeg{\varphi(s)} = n_x $.
		\end{itemize}
	
		\begin{mdframed}[style=Esempio]
			\paragraph{Esempio}
			Consideriamo la matrice e il polinomio caratteristico dell'esempio precedente:
			\[ 
				\varphi(s) = (s-1)(s-2) = s^2 - 3s + 2 
			\]
			\[ 
				\varphi(A) = A^2 + -3A + 2I = 
				\begin{bmatrix}
					1 & 3\\
					0 & 2
				\end{bmatrix}
				\begin{bmatrix}
					1 & 3\\
					0 & 2
				\end{bmatrix} -
				\begin{bmatrix}
					3 & 9\\
					0 & 6
				\end{bmatrix} +
				\begin{bmatrix}
					2 & 0\\
					0 & 2
				\end{bmatrix} =
				\begin{bmatrix}
					0 & 0\\
					0 & 0
				\end{bmatrix}
			\]
		\end{mdframed}

	\subsection{Polinomio minimo}
		Il polinomio minimo $ m(s) $ \'e il polinomio annullante, monico e di grado pi\'u basso per A.
		
	\subsubsection{Propriet\'a}
		\begin{itemize}
			\item 
				\[ 
					m(s) \subseteq \cdot\ \varphi(s)
				\]
				$ \subseteq \cdot $ significa che tutte le radici di $ \varphi(s) $ sono anche radici di $ m(s) $, eventualmente con molteplicit\'a minore.
			\item 
				$ m(s) $ \'e calcolabile come il mcm di tutti i denominatori dei termini non nulli della matrice $ (sI - A)^{-1} $. Il suo grado \'e: $ \pDeg{m(s)} \leq n_x $.
		\end{itemize}
		
		\begin{mdframed}[style=Esempio]
			\paragraph{Esempio}
			Per fare l'inversa di una matrice diagonale, bisogna invertire i suoi elementi. 
			\[
				A =
				\begin{bmatrix}
					0 & 0\\
					0 & 0
				\end{bmatrix} \qquad (sI - A)^{-1} = 
				\begin{bmatrix}
					s & 0\\
					0 & s
				\end{bmatrix}^{-1} = 
				\begin{bmatrix}
					\dfrac{1}{s} & 0\\
					0 & \dfrac{1}{s}
				\end{bmatrix}
			\]
			\[ 
				m(s) = mcm( s, s) = s
			\]
		\end{mdframed}
	
		\begin{mdframed}[style=Esempio]
			\paragraph{Esempio}
			Per fare l'inversa di una matrice triangolare, gli elementi sulla diagonale si invertono, gli altri bisogna calcolarli.
			\[
				A =
				\begin{bmatrix}
					0 & 1\\
					0 & 0
				\end{bmatrix} \qquad (sI - A)^{-1} = 
				\begin{bmatrix}
					s & -1\\
					0 & s
				\end{bmatrix} ^{-1} =
				\begin{bmatrix}
					\dfrac{1}{s} & \dfrac{1}{s^2}
					\\[1em]
					0 & \dfrac{1}{s}
				\end{bmatrix}
			\]
			\[
				m(s) = mcm( s, s^2, s) = s^2
			\]
		\end{mdframed}

		\begin{mdframed}[style=Esempio]
			\paragraph{Esempio di errore}
			\[
				(sI-A)^{-1} =
				\begin{bmatrix}
					\dfrac{1}{s} & \dfrac{1}{s^2}
					\\[1em]
					\dfrac{1}{s+1} & \dfrac{1}{s}
				\end{bmatrix}
			\]
			\[
				m(s) = mcm \left\lbrace s, (s+1), s, s^2 \right\rbrace = s^2(s+1)
			\]
			Ma questo risultato \'e impossibile perch\'e $ \pDeg{m(s)} = 3 $ mentre la matrice \'e $ 2 \times 2 $. Questo significa che la matrice data non pu\'o derivare da un sistema lineare, quindi non ha senso svolgere ulteriori calcoli si essa.
		\end{mdframed}

	\section{Trasformata della soluzione dell'equazione di stato}
		Calcolo la trasformata di $ \dot{\vec x}(t) = A \vec x(t) + B \vec u(t) $ con la propriet\'a della derivata:
		\[
			s \vec X(s) - \vec x(0^-) = A \vec X(s) + B \vec U(s)
		\]
		\[
			s \vec X(s) - A \vec X(s) = \vec x(0^-) + B \vec U(s)
		\]
		\[
			(sI - A) \vec X(s) = \vec x(0^-) + B \vec U(s)
		\]
		\begin{equation}
			X(s) = (sI-A)^{-1} \vec x(0^-) + (sI-A)^{-1} B \vec U(s)
		\end{equation}
		Analogamente la trasformata della seconda equazione $ \vec y(t) = C \vec x(t) + D \vec u(t) $:
		\begin{equation}
			\vec Y(s) = C (sI-A)^{-1} \vec x(0^-) + [C(sI-A)^{-1}B + D]\ \vec U(s)
		\end{equation}
		Da quest'ultima ricaviamo la funzione di trasferimento:
		\[
			T(s) = C (sI-A)^{-1} B + D
		\]
		Le matrici associate alle varie risposte con i rispettivi polinomi caratteristici e minimi:
		\begin{align*}
			&X_l\ (n_x\ \times\ n_x):\ (sI-A)^{-1} &&\longrightarrow &m(s), \varphi(s)
			\\
			&X_f\ (n_x\ \times\ n_u):\ (sI-A)^{-1}B &&\longrightarrow &m_c(s), \varphi_c(s)
			\\
			&Y_l\ (n_y\ \times\ n_x):\ C(sI-A)^{-1} &&\longrightarrow &m_o(s), \varphi_o(s)
			\\
			&Y_f\ (n_y\ \times\ n_u):\ C(sI-A)^{-1}B &&\longrightarrow &m_{co}(s), \varphi_{co}(s)
		\end{align*}
		Le ultime tre matrici sono combinazioni lineari della prima $ (sI-A)^{-1} $, quindi a denominatore non potranno comparire ulteriori termini. Allora per i polinomi si ha:
		\[ 
			\begin{array}{ccc}
								&\subseteq \varphi_c(s) &\\
				\varphi_{co}(s)	& 					  	&\subseteq \varphi(s)\\
								&\subseteq \varphi_o(s) &\\
			\end{array} \qquad
			\begin{array}{ccc}
						  &\subseteq m_c(s) &\\
				m_{co}(s) & 				&\subseteq m(s)\\
						  &\subseteq m_o(s) &\\
			\end{array}
		\]
		
		\begin{mdframed}[style=Esempio]
			\paragraph{Esempio}
			Dato il sistema:
			\[
				\begin{cases}
					\dot x =
					\begin{bmatrix}
						0 & 1\\
						0 & 0
					\end{bmatrix} x + 
					\begin{bmatrix}
						0\\
						1
					\end{bmatrix} u
					\\[1em]
					y = 
					\begin{bmatrix}
						1 & 1
					\end{bmatrix}  x
				\end{cases}
			\]
			Calcolare $ x(t) $ e $ y(t) $ quando $ x(0^-) = \begin{bmatrix} 1\\ 2 \end{bmatrix} $ e $ u(t) = \gr $.
			
			Calcoliamo le trasformate delle soluzioni:
			\begin{align*}
				X(s) &= (sI-A)^{-1} x(0^-) + (sI-A)^{-1} B\ U(s) =
				\\
				&= 
				\begin{bmatrix}
					\dfrac{1}{s} & \dfrac{1}{s^2}
					\\[1em]
					0 & \dfrac{1}{s}
				\end{bmatrix}
				\begin{bmatrix}
					1
					\\[1em]
					2
				\end{bmatrix} + 
				\begin{bmatrix}
					\dfrac{1}{s} & \dfrac{1}{s^2}
					\\[1em]
					0 & \dfrac{1}{s}
				\end{bmatrix}
				\begin{bmatrix}
					0
					\\[1em]
					1
				\end{bmatrix} \dfrac{1}{s} = 
				\begin{bmatrix}
					\dfrac{1}{s}+\dfrac{2}{s^2}+\dfrac{1}{s^3}
					\\[1em]
					2\dfrac{1}{s}+\dfrac{1}{s^2}
				\end{bmatrix}
			\end{align*}
			\[
				x(t) = 
				\begin{bmatrix}
					1+2t+\dfrac{1}{2} t^2
					\\[.5em]
					2+t
				\end{bmatrix} \gr
			\]
			\[
				y(t) = 
				\begin{bmatrix}
					1 & 1
				\end{bmatrix}
				x(t) = (3 + 3t + \dfrac{1}{2} t^2)\ \gr
			\]
		\end{mdframed}
\end{document}